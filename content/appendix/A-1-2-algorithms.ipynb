{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "section: \"Machine learning algorithms and functions used for numerical prediction\"\n",
    "goal: \"Understand the algorithms used for prediction in the first part.\"\n",
    "time: \"x min\"\n",
    "prerequisites: \"Basics about machine learning\"\n",
    "level: \"Beginner and advanced\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture is about data quality, so we do not want to focus too much on the task of prediction, but more on the data themselves. For this reason, the prediction functions have been simplified as much as possible, and we will use some simple algorithms from some Python libraries.\n",
    "\n",
    "To understand how a simple task of supervised learning is led, refer to the introductory part (link) __TODO: link to the introduction about supervised learning__.\n",
    "\n",
    "This section is not mandatory to understand the rest of the course, but if you are curious about the functions used for prediction, we will now go through them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 kinds of supervised prediction tasks: classification and regression. Here, they will be tackled the same way, only the algorithm used and the way of measuring the performance change. We use a simple K-Nearest-Neighbors (KNN) algorithm for both types of prediction tasks. The KNN algorithm is simple to understand and to implement and usually gives good results, that is why we chose it for this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The K-Nearest-Neighbors algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN algorithm classifies a new instance based on the idea that \"similar objects are close to each other\". The ground idea of the algorithm is to calculate a distance metrics between each instance, and to classify similarly two instances that are close to each other.\n",
    "\n",
    "Let's look at this in details, with an example.\n",
    "\n",
    "Let's say we want to classify some types of flowers: we have 3 classes or iris flowers (Iris setosa, Iris versicolor and Iris virginica). We have the petal length and width for a few samples of each flower, represented on this graph:\n",
    "\n",
    "![text](iris.png)\n",
    "\n",
    "The different types of iris seem easy to distinguish on the graph, based on the petal length and width.\n",
    "\n",
    "To classify an instance, the KNN algorithm measures the distance of the instance to every other instance in the training dataset. Then, according to the value of ``K`` (a parameter of the model that has to be specified by the user), the algorithm then looks at the class of the ``K`` instances with the smaller distance to the new instance. The majority class among the K nearest instances is the class that is predicted for the new algorithm. Let's look together at a small example:\n",
    "\n",
    "![text](iris2.png)\n",
    "\n",
    "In black, a new instance has been represented: we do not know the class of this instance and want the algorithm to predict it. The model will first find the nearest K instances (in this example, we took ``K = 5``):\n",
    "\n",
    "![text](iris3.png)\n",
    "\n",
    "The algorithm now will look at the class of these K instances. In our example, we have 3 points of the class Iris-versicolor (orange) and 2 of the class Iris-virginica (green): the majority class of the K nearest neighbors is then Iris-versicolor, and the instance is classified as such.\n",
    "\n",
    "For a regression problem, the algorithm works the same way, and to predict the value of the new instance, it takes the mean value of the K nearest points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, the library ``sklearn`` contains some implementation of the common machine learning algorithms. We use the function [KNeighborsRegressor()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) to build the model.\n",
    "\n",
    "At first, we split the dataset into training and testing sets with the function [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from the ``sklearn`` library. Then, to avoid any error as the KNN algorithm does not handle missing values, we fill the missing values with 0, using the Pandas function [fillna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) on the dataframe.\n",
    "\n",
    "The model is then instanciated, here we take a value of ``25`` for the parameter ``K``. Once the model is instanciated, we train it with the method ``fit()``. Then we get the predictions on the testing set with the method ``predict()``. Finally, the function returns the predictions and the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regression\n",
    "def knn_regression(df, x,  y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df[x], df[y], test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    x_train = x_train.fillna(value = 0)\n",
    "    x_test = x_test.fillna(value = 0)\n",
    "    y_train = y_train.fillna(value = 0)\n",
    "    y_test = y_test.fillna(value = 0)\n",
    "    \n",
    "    knn = KNeighborsRegressor(n_neighbors = 25)\n",
    "    knn.fit(x_train, y_train)\n",
    "    predictions = knn.predict(x_test)\n",
    "    \n",
    "    return predictions, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented an additional function called ``knn_reg_train()`` for the purpose of the exercise. This function is used when we want to specify the training set ourselves. It returns the trained model, on which the user can further make his own predictions with his own testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regression\n",
    "def knn_reg_train(df_train, x,  y):\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    \n",
    "    x_train = df_train[x].fillna(value = 0)\n",
    "    y_train = df_train[y].fillna(value = 0)\n",
    "    \n",
    "    knn = KNeighborsRegressor(n_neighbors = 25)\n",
    "    knn.fit(x_train, y_train)\n",
    "    \n",
    "    return knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the classification, we work the same way as for the regression function. Except we do not fill the missing values, because we cannot create a new class on the data.\n",
    "\n",
    "The model used here is [KNeighborsClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) from the ``sklearn`` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classification\n",
    "def knn_classification(df, x,  y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(df[x], df[y], test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = 25)\n",
    "    knn.fit(x_train, y_train)\n",
    "    predictions = knn.predict(x_test)\n",
    "    \n",
    "    return predictions, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
